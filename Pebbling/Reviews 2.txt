Dear Bruno Woltzenlogel Paleo,

We regret to inform you that your submission

13: Greedy Pebbling: Towards Proof Space Compression

has not been accepted for publication at SAT 2014. The final reviews
for your submission are appended at the end of this message.

SAT 2014 received a total of 51 regular, 15 short, and 12 tool paper
submissions. Three papers were returned without review, being
outside the scope of the SAT Conference, as specified in the call for
papers. Papers were reviewed only for the category in which they were
submitted; there was no shifting to a different category.

Each paper received at least four reviews. An author response process was
implemented. In many cases, several rounds of intense discussions among
the reviewers and other PC members were conducted before decisions were made.
Many reviewers also updated their reviews to reflect how they have taken
the author responses into account. Where necessary, additional reviews
were solicited for individual papers.

Although we realize this outcome is disappointing, we hope that you will
consider other ways to participate in SAT 2014.
Notice that SAT 2014 is hosting several affiliated workshops that will
take place before and after the conference. These workshops
are an ideal opportunity to share new results and work in progress with
colleagues, often in a less formal, more interactive setting.
For details, visit http://baldur.iti.kit.edu/sat2014/workshops.html .
We hope to see you in Vienna for SAT 2014!

Best regards,

Uwe Egly and Carsten Sinz
SAT 2014 PC Co-chairs


----------------------- REVIEW 1 ---------------------
PAPER: 13
TITLE: Greedy Pebbling: Towards Proof Space Compression
AUTHORS: Bruno Woltzenlogel Paleo and Andreas Fellner

OVERALL EVALUATION: 0 (borderline paper)
REVIEWER'S CONFIDENCE: 4 (high)
Relevance: 2 (low)
Originality: 3 (fair)
Significance: 2 (low)
Technical Quality: 2 (poor)
Readability and Organization: 3 (fair)

----------- REVIEW -----------
The authors consider a pebbling game on graphs. This game can be used for estimating the amount of memory needed for checking proofs produced by SAT-solvers. A pebbling strategy defines a way to check a proof, requiring as much memory as pebbles. This is not surprising, since pebbling games have been extensively used in the literature in order to measure the space in resolution refutations. The only difference between the game considered by the auhors and the one used for resolution, is the fact that in this paper every node can be pebbled only once. This does not allow for time-space trade offs and brings the decision of whether a number of pebbles sufices for a checking proof, from PSPACE to NP. After definig these concepts the authors introduce several heuristic methods for computing a good pebbling strategy. The different methods have been implemented and a table of results is given. From the results follows that the best heuristic is one that can be best explained from a
bottom up point of view.

The paper has very little theoretical content. The most important part of the paper (Section 7)  with the description of the heuristic methods is not very detailed. In my opinion its only merit comes from the experimental part. 



Some observations: 

Since most SAT-solvers are based on DPLL algorithms, the proof graph is not an arbitrary graph, but a tree. Considering this, it should be possible to compute the optimal pebble number of a proof and compare it with the number obtained by the different heuristics. 

The notation in definition  is not explained. 

Page 7 after the algorithm.  "sup-optimal" should be "sub-optimal"


----------------------- REVIEW 2 ---------------------
PAPER: 13
TITLE: Greedy Pebbling: Towards Proof Space Compression
AUTHORS: Bruno Woltzenlogel Paleo and Andreas Fellner

OVERALL EVALUATION: 0 (borderline paper)
REVIEWER'S CONFIDENCE: 3 (medium)
Relevance: 4 (high)
Originality: 4 (good)
Significance: 4 (high)
Technical Quality: 4 (good)
Readability and Organization: 2 (poor)

----------- REVIEW -----------
The authors propose different approaches to compressing proofs of
unsatisfiability produced by resolution based SAT solvers. That is,
for a proof of unsatisfiability the authors are interested in finding
the minimum amount of clauses that need to be kept in memory in order
to verify such a proof. This question can be naturally connected to
the question of determining the cost of playing a particular pebble
game on graphs that correspond to proofs. One way of looking at a
resolution refutation is as a directed acyclic graph where every
clause is represented by some vertex and there are edges going from
vertex u to vertex v if the clause corresponding to the vertex u was
used in deriving the clause corresponding to the vertex v (note that
the authors invert the direction of edges in their paper). With this
representation of resolution proof, we can minimize space by finding
the minimal number of pebbles needed to pebble this graph, where we
are allowed to pebble a vertex only if its predecessors are pebbled,
we can remove an arbitrary vertex, and every vertex can be pebbled at
most once.

As the determining the exact minimal number of pebbles for this game
is NP-complete, the authors consider two ways of searching through the
space of all possible pebblings and several heuristics that guide this
search. The problem of finding the best pebbling reduces to the
problem of finding the optimal topological order on the vertices and
the authors propose two ways of constructing such an order: top-down
which traverses the graph from axioms to the empty clause, and
bottom-up which traverses the graph from the empty clause to the
axioms. They also propose four different heuristics that can be used
to determine the exact node that we should pebble at the next
step. Two of them are simple and determine the score of each vertex by
looking only at that vertex, while the other two are more involved and
they determine the score of a vertex by also looking at the scores of
the vertices that are close by.

The authors ran some experiments with both types of search and four
heuristics, and they concluded that bottom-up search often works
better than the top-down. Also, using more involved heuristics
produced slightly better results than using the simple ones, but at a
cost of much slower execution. 

The paper presents new ideas on how to compress proofs, with some
potentially interesting heuristic algorithms that can be used.
Summing up, however, the theoretical content of the paper does not seem too
significant (not to say weak), and so the paper should be assessed on
how convincing the experimental results are. I am not convinced that
the experimental results in themselves are strong enough to merit
acceptance.

I want to stress, though, that I think this is an interesting paper,
and that it definitely has potential to be published in some (future)
SAT conference in some form. However, the current submission is hurt
by appearing to be --- frankly speaking --- simply half-baked. In
addition to what was already mentioned above, definitions are sloppy
(and sometimes wrong), discussions of relevant previous literature is
sometimes missing, and the results as such are not too convincing
(although they do seem like a promising start).

Detailed comments for the authors:

- Definition 1 and Definition 4 are very hard to parse the way they
 are written now. Maybe the authors should consider rephrasing them
 or at least adding intuitive descriptions of the definitions
 somewhere before or after them. Also, the direction of the edges in
 Definition 1 seems to be non-standard as commented before in the
 review. In fact, Def 1 actually seems to be wrong since (as far as this 
 reviewer can see) it only allows for tree-like resolution proofs.

- On page 3, first paragraph, the definition of children of the node
 seems to be what is usually a parent of the node in a DAG. This
 would be fixed if the direction of edges was inverted, but that
 might introduce some other terminology problems elsewhere.

- The list of references in the discussion of pebbling at the start of
 Sec 3 seem somewhat random. The authors might want to cite

Jakob Nordstrom. Pebble Games, Proof Complexity, and Time-Space
Trade-offs. Logical Methods in Computer Science, volume 9, issue 3,
article 15, September 2013

 for an overview of the connections between proof complexity and
 pebbling. Also, when citing works by Ben-Sasson and Nordstrom with
 co-authors, it would seem to make sense to add more recent references
 such as

Eli Ben-Sasson. Size-Space Tradeoffs for Resolution. SIAM Journal on
Computing, 38(6), 2511--2525.

Eli Ben-Sasson and Jakob Nordstrom. Understanding Space in Proof
Complexity: Separations and Trade-offs via Substitutions. In
Proceedings of the 2nd Symposium on Innovations in Computer Science
(ICS '11), pages 401-416, January 2011.

Chris Beck, Jakob Nordstrom, and Bansheng Tang. Some Trade-off Results
for Polynomial Calculus. In Proceedings of the 45th Annual ACM
Symposium on Theory of Computing (STOC '13), pages 813-822, June 2013.

- In connection with Def 5 there should be a reference to the 

Jacobo Tor√°n. Lower Bounds for Space in Resolution. In Proc. CSL 1999,
pages 362-373

 which has a very similar definition. 

- The contribution of Section 5 is not quite clear. It is not so surprising
 that encoding the problem of finding a good pebbling strategy as a SAT
 instance gives horribly large instances, and this seems to be the main
 contribution of this section.

- In Section 5, the second formula that is defined seems to have a
 typo in that the last variable p_{y, i, n} should be negated.

- In Example 1/2, I am not sure how are you able to pebble this graph
 in three pebbles, or even four. So maybe expanding a bit on it, if
 it is correct, would be helpful. In Example 2 in particular, when
 pebbling the vertex 6 there should be at least four pebbles in the
 graph on vertices: 3, 4, 5, and 6.

- In formulas in Section 7.3, most K^G formulas miss the parameter v.

- The tables in the paper are not very readable, especially Table
 2. The reviewer would recommend using much less lines between cells,
 in that all vertical lines should be dropped, and horizontal ones
 might separate into groups Ch, LC, Dist(1), and Dist(3), while Dc
 would be completely separated from the rest and maybe additionally
 subdivided. Also, it would be helpful if the best results (overall
 or in the group) were in bold-face so that they are easier to spot.

- There appear to some problems with national characters disappearing in 
 the references, e.g. in reference [7].


----------------------- REVIEW 3 ---------------------
PAPER: 13
TITLE: Greedy Pebbling: Towards Proof Space Compression
AUTHORS: Bruno Woltzenlogel Paleo and Andreas Fellner

OVERALL EVALUATION: 0 (borderline paper)
REVIEWER'S CONFIDENCE: 3 (medium)
Relevance: 4 (high)
Originality: 4 (good)
Significance: 4 (high)
Technical Quality: 2 (poor)
Readability and Organization: 3 (fair)

----------- REVIEW -----------
This paper describes postprocessing to reduce the size of
proofs as produced by SAT solvers - in particular resolution proofs
are considered). To this end a pebbling approach is applied which
helps to identify parts of the proof which are obsolete for the final
result and which therefore can be omitted. So the proof size can
be reduced. For practical realization several variants of
this approach are considered (bottom-up, top-down plus some
heuristics).

The paper contains very interesting ideas and the topic is
certainly of practical relevance. However, there are several
issues (especially in the theoretical part)
of the paper which have to be fixed to improve readability.

First of all, it seems that Definition 1 has some problems.
As this definition is essential for the paper, it is really
important to formulate this crystal clear.
For example, the L appears out of nowhere. At least it should be
mentioned that the proof under consideration is defined over
alphabet L. Then there is something strange with the inductive
definition: a DAG <V, E, Gamma>  is proof of a clause Gamma iff
(1) Gamma is a clause , Gamma^ denotes some proof ...
(2) ...
This I don't understand. Why is the Gamma in the DAG? What exactly
are the nodes a proof and what is the Gamma?
Later in the paper DAGs (pairs of vertices and edges) and proofs
(these triples) are mixed in the definitions. Please check
if this is intended.

Definition 2 is ok, but rather informal. I would prefer if it
was not given in prose but in a formally concise manner. In particular,
rule 3 was ambiguous to me and it became not clear before the
2nd page. Further, parts of the paragraph after rule3 should be
removed from the definition environment - it is a detailed explanation,
but not part of the definition.

Definition 4 needs some further explanation. Maybe an example could
help. For me the role of ro(psi) is not clear. And why is it defined
on a DAG when the topological order (def 3) is defined on a proof?

In Theorem 2, what is O(m), Omega(m!)? What is the message of Theorem 2?

In the experimental section, table 1 could be better described. The
way the data is given it is not very expressive and it would be nice
if some characteristics for the different benchmark sets could be
provided.
In fig 5 and 6 always the best result seems to be shown. It would be
useful, if something similar was given for each approach. Then a
better comparison would be possible. In fig 6 there is at least the
distinction between bottom up and top-down. Also, the arrangement
of Table 2 is not ideal, because information is hard to aggregate.
Also I could imagine that absolute performance for the individual
sets would be more clear (at least it could be also provided).

Surprisingly, the paper contains hardly an related work although
one of the authors has several publications on this topic. Even if
this approaches work in a different way then the proposed pebbling
approach some discussion emphasizing the differences would strengthen
the contribution of this paper. Further, [1] should be included
in related work explicitly (at the moment this work is mentioned
without referencing it).

In the abstract, the content of the paper should be advertised.
In particular,  it should be pointed out in a more prominent manner
that the problem of compressing large proofs as produced by SAT
solvers for unsatisfiable formulas is tackled. Therefore, pebbling
games are used.

[1] Marijn Heule, Warren A. Hunt Jr., Nathan Wetzler: Trimming while
checking clausal proofs. FMCAD 2013: 181-188


----------------------- REVIEW 4 ---------------------
PAPER: 13
TITLE: Greedy Pebbling: Towards Proof Space Compression
AUTHORS: Bruno Woltzenlogel Paleo and Andreas Fellner

OVERALL EVALUATION: 0 (borderline paper)
REVIEWER'S CONFIDENCE: 4 (high)
Relevance: 4 (high)
Originality: 3 (fair)
Significance: 3 (medium)
Technical Quality: 4 (good)
Readability and Organization: 3 (fair)

----------- REVIEW -----------
The question of postprocessing a resolution refutation in order to add deletion
operations is a natural one. Yet the achievements of the paper seem
however a bit thin to me, and the presentation, though a good effort is made,
has specific weaknesses, which should be addressed.

Obviously there are close connections to the space complexity of resolution,
and thus an overview is needed, with a discussion of the connections. There
are some comments, but they are only of a technical nature (and the
Introduction doesn't discuss the topic at all).

The presentation is unneccessarily technical, using ad-hoc symbols just for
abbreviation (they do not serve any systematical purpose).

The introduction mentions as motivation only the preprocessing of a refutation,
to make live easier for the proof checker, memory-wise --- intuitively, one
expects the task of space compression at least as hard as proof checking?

Further details:

You spell SAT sometimes as "Sat", sometimes as "sat", but "SAT" is the
standard.

A "clause" is a set of literals -- so you allow tautological clauses?

Definition 1 must be accompanied by explanations. Due to the recursive nature,
the definition looks like a tree-resolution proof --- dag's only enter the
picture by having V_L, V_R not disjoint. This needs to be discussed (that the
identity of the vertices plays an important role).

Part 1 is formulated in a misleading way: If you start a sentence with "If",
then an assertion (which is true or false) is expected, not a definition.
Better is "For a clause Gamma let hat{Gamma} ...". Then "some proof" is
also misleading (especially in the context, where one expects a statement),
since it is essentially "the proof", up to the choice of the vertex label.
I think you don't gain anything by the recursive definition, and the ordinary
definition as a dag with some labels fulfilling basic properties is easier.
There are other problems at the level in the paper, which could be avoided
if not so many symbols would be introduced.

You need to specify that (V,E,Gamma) has precisely one sink.

Instead of symbols like "rho", just use "root" (using \DefineMathOperator,
see below).

Section 3: You need to explain the connections to space complexity in
proof theory. You start with pebbling, and then just add a definition of space in
Section 4, without references! However, you need to start with a thorough review of (clause)
space for resolution (dag- and tree-like), and from that *derive* pebbling -- that's
the logical order *and* the historical order.

It seems not justified to call your version of pebbling "the pebbling game".

The paragraph after Definition 2 is very unclear. For example, two of the
three rules allow something, while one forbids something. This makes it
rather confusing. So the "This allows" is very unclear (what does "This"
refer to?) --- avoid "this" in general (just avoid abbreviations in general).
(The point is that your "this" refers to something very precise, while
for example the "this" in "This makes it rather ..." is just a vague "this",
typical for natural language talk (besides actually pointing at something).)

Definition 3: It just reads awkward, to have the subscript "T" in "<", without
serving any function.

Definition 4 reads rather awful. The function "pebble(v)" is undefined.
What is "t" ? Why does "S(psi, rho(psi), t)" has the root as an argument?
Don't just use symbols for this purely technical things (C, S, U ...), but
if notation is needed, then spend some thought on it, so that one can easily
memorise it (but likely many of these notations aren't needed, since you do not
prove mathematical laws for them).

Many commas are missing, so for example in Definition 4 before "represented".

It is a misuse of LaTex to write e.g. $pebble(v)$, since this means p times
e times b ... times v. Use \mathrm{pebble}, or, better, \DeclareMathOperator
form AmsTex.

For Theorem 1 you only provide a sketch, but where is the complete proof?
Is there a technical report? It is not in the attachment.

The notion of "that pebble nodes according to the topological order" is not
defined. In general, what is missing in the paper is the connection between
the general explanations (too vague) and the notations (too precise, so to
speak). Definitions which specify "topological order", "according to" etc.,
using mostly ordinary language, are most useful here (there is also no need
to be very precise here, since the content is very clear).

Definition 5 doesn't discuss at all the literature! Not a specific article is
needed, but a review of the literature. (To start with, there are various definitions
and variations on "space".)

The proof of Theorem 2 is very unclear (to start with, what is psi_m ?).

Page 6: I would put a colon after the heading of each of the five points.

Comma missing after "However".

Subsection 6.1: what does "remove pebbles if *possible*" mean?

Algorithm 1 is hard to read --- just explain additionally what each line
is doing.

"figure 1" -> "Figure 1".

As I said, many commas can be inserted to increase clarity. For example,
Section 7.1, "where <_T = " should be embraced with commas.

(I just notice that you distinguish between "::" and ":::" --- this is
a computer science paper, not an exercise in programming. And an order is
in any case not a list (but a relation), so any form of concatenation is not
appropriate here. But these issues *shouldn't matter* here!)

References 9, 10, 11 have editorial problems.