\documentclass{llncs}
\usepackage{etex}

\usepackage{xcolor}
\usepackage{enumitem,amsmath,amssymb}
\usepackage{breakurl}    % used for \url and \burl
\usepackage[linesnumbered,boxed,noline,noend]{algorithm2e}
\def\defaultHypSeparation{\hskip.1in}

\usepackage{tikz}
\usepackage{subfig}
\usepackage{array,booktabs,multirow}
\usepackage{placeins}

\usepackage{logictools}
\usepackage{prooftheory}
\usepackage{comment}
\usepackage{mathenvironments}
\usepackage{drawproof}
\usepackage{bussproofs}
\usepackage{tensor}
\usepackage{mathtools}
\usepackage{amsmath}

\usepackage{graphicx}
%\usepackage{caption}
%\usepackage{subcaption}

\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\renewcommand{\floatpagefraction}{0.75}


\newcommand{\freevar}[1]{\mathrm{FV}(#1)}

\newcommand{\Vertices}[1]{V_{#1}}
\newcommand{\Edges}[1]{E_{#1}}
\newcommand{\Conclusion}[1]{\clause_{#1}}

\newcommand{\axiom}[1]{\widehat{#1}}
\newcommand{\n}{v}
\newcommand{\raiz}[1]{\rho(#1)}

\newcommand{\pedge}[3]{\ensuremath{\raiz{#1} \xrightarrow{#2} \raiz{#3}}}


\newcommand\inlineeqno{\stepcounter{equation}\ (\theequation)}


% Contraction
\newcommand{\con}[3]{\lfloor #1 \rfloor_{#2}^{#3}}

% Resolution
%\newcommand{\res}[6]{#1 \tensor[^{#2}_{#3}]{\odot}{^{#4}_{#5}} #6}
%\newcommand{\res}[6]{#1 \prescript{#2}{#3}{\odot^{#4}_{#5}} #6}

\newcommand{\res}[4]{\mathrel{\operatorname*{\odot}_{#1 #3}^{#2 #4}}}

\title{Partial Regularization of\\ First-Order Resolution Proofs}

\author{
  Jan Gorzny\inst{1}
  \thanks{Supported by the Google Summer of Code 2014 program.}
  \and 
  Bruno Woltzenlogel Paleo\inst{2,3}
  %\thanks{Supported by the Austrian Science Fund, project P24300.}
}

\authorrunning{J.\~Gorzny \and B.\~Woltzenlogel Paleo}

\institute{
  \email{jgorzny@uvic.ca}, University of Victoria, Canada
  \and 
  \email{bruno@logic.at}, Vienna University of Technology, Austria
  \and 
  Australian National University
}




\begin{document}

\maketitle


\begin{abstract}
This paper describes the generalization of the 
proof compression algorithm
\RecyclePivotsIntersection 
%\texttt{RecyclePivots\-WithIntersection}
from propositional to first-order logic. The generalized algorithm performs partial regularization of resolution proofs containing resolution and factoring inferences with \emph{unification}, as generated by many automated theorem provers. An empirical evaluation of the generalized algorithm and its combinations with \SFOLowerUnits is also presented.
\end{abstract}


\setcounter{footnote}{0}

\section{Introduction} 

First-order automated theorem provers, commonly based on resolution and superposition calculi, have recently achieved a high degree of maturity. Proof production is a key feature that has been gaining importance, since proofs are crucial for applications that require certification of a prover's answers or information extractable from proofs (e.g. unsat cores, interpolants, instances of quantified variables). Nevertheless, proof production is non-trivial \cite{SchultzAPPA}, and the best, most efficient provers do not necessarily generate the best, least redundant proofs.

For proofs using propositional resolution generated by SAT- and SMT-solvers, there is a wide variety of proof compression techniques. Algebraic properties of the resolution operation that might be useful for compression were investigated in \cite{bwp10}.
Compression algorithms based on rearranging and sharing chains of resolution inferences have been
developed in \cite{Amjad07} and \cite{Sinz}.  Cotton \cite{CottonSplit} proposed an algorithm that
compresses a refutation by repeatedly splitting it into a proof of a heuristically chosen literal $\ell$
and a proof of $\dual{\ell}$, and then resolving them to form a new refutation.  The {\ReduceReconstruct} algorithm \cite{RedRec} searches for locally redundant
subproofs that can be rewritten into subproofs of stronger clauses and with fewer resolution steps.
A linear time proof compression algorithm based on partial
regularization was proposed in \cite{RP08} and improved in \cite{LURPI}.

In contrast, there has been much less work on simplifying first-order proofs. For tree-like sequent calculus proofs, algorithms based on cut-introduction \cite{BrunoLPAR,Hetzl} have been proposed. However, converting a DAG-like resolution or superposition proof, as usually generated by current provers, into a tree-like sequent calculus proof may increase the size of the proof. For arbitrary proofs in the TPTP \cite{TPTP} format (including DAG-like first-order resolution proofs), there is a simple algorithm \cite{LPARCzech} that looks for terms that occur often in any TSTP \cite{TPTP} proof and introduces abbreviations for these terms. 

The work reported in this paper is part of a new trend that aims at lifting successful propositional proof compression algorithms to first-order logic. Our first target was the propositional {\LowerUnits} algorithm, which delays resolution steps with unit clauses, and its lifting resulted in the 
{\SFOLowerUnits} 
({\GFOLU}) algorithm \cite{GFOLU}. Here we continue this line of research by lifting the 
%\RecyclePivotsIntersection 
\texttt{Recycle\-PivotsWithIntersection}
({\RPI}) algorithm \cite{LURPI}, which is an improvement of the \texttt{RecyclePivots} ({\RP}) algorithm \cite{RP08}, providing better compression on proofs where nodes have several children. 

%TODO: edit this again
Section \ref{sec:res} introduces the first-order resolution calculus and the notations used in this paper. Section \ref{sec:Challenges} discusses the challenges that arise in the first-order case (mainly due to unification), which are not present the propositional case. Section \ref{sec:FORPI} describes an algorithm that overcomes these challenges. Section \ref{sec:exp} concludes the paper by presenting experimental results obtained by applying this algorithm, and also its combinations with {\GFOLU}, on hundreds of proofs generated with the {\SPASS} theorem prover. 



\input{sec-Resolution}

\section{The Propositional Algorithm}

{\RPI} removes \emph{irregularities}, which are resolution inferences with a node $\eta$ when the resolved literal (a.k.a. \emph{pivot}) occurs as the pivot of another inference located below in the path from $\eta$ to the root of the proof. In the worst case, regular resolution proofs can be exponentially bigger than irregular ones, but {\RPI} takes care of regularizing the proof only partially, removing inferences only when this does not enlarge the proof.

ToDo: Informal textual description of the propositional algorithm, explaining what safe literals are. Refer reader to the CADE 2011 paper (where RPI is described) for a formal description of the propositional algorithm. Consider adding the formal description to an appendix in this paper, for the convenience of the reviewer.

The {\RPI} and the {\RP} algorithms differ from each other mainly in the
computation of the safe literals of a node that has many children. While the former 
returns the intersection as shown in Algorithm~\ref{algo:SetSafeLiterals}, the latter
returns the empty set. 
Further, while in {\RPI} the safe literals of the root node contain all the literals of the root clause, in {\RP} the root node is always assigned an empty set of literals. 

\input{sec-Challenges}
\input{sec-FORPI}
\input{sec-Exp}



%\section{Conclusions and Future Work}
%TODO: this section?
%{\FORPI} continues to support the idea of listing propositional proof compression algorithms to the first-order case. The experimental results discussed in the previous continue to be encouraging, and are consistent with trends observed in the propositional case. 

%\paragraph{Acknowledgments:}


\begin{footnotesize}
%\bibliographystyle{splncs}
\bibliographystyle{plain}
\bibliography{biblio}
\end{footnotesize}
\appendix
\input{sec-PropRPI}
\end{document}

% vim: tw=100
